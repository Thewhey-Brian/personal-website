{
  "title": "Self-Supervised Learning Methods on Corss-tissye Spatial Transcriptomics Data (MOSTA)",
  "summary": "Evaluating 8 SSL methods with 3 GNN architectures on large-scale mouse embryo spatial transcriptomics data reveals interesting performance of reconstruction-based approaches",
  "status": "completed",
  "role": "Research & Analysis",
  "stack": [
    "PyTorch",
    "PyTorch Geometric",
    "Python",
    "Self-Supervised Learning",
    "Graph Neural Networks",
    "Spatial Transcriptomics"
  ],
  "images": [],
  "tags": [
    "deep learning",
    "self-supervised learning",
    "bioinformatics",
    "spatial transcriptomics",
    "representation learning",
    "developmental biology"
  ],
  "featured": true,
  "startDate": "2025-09-30T07:00:00.000Z",
  "body": {
    "raw": "\n# Self-Supervised Learning Methods on Corss-tissye Spatial Transcriptomics Data (MOSTA)\n\nBuilding on the [previous exploration with SiT mouse brain data](/projects/gnn-ssl-sit), this study evaluates the same self-supervised learning framework on a substantially larger and more complex dataset to assess scalability, cross-tissue generalizability, and method robustness.\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Methods](#methods)\n3. [Results](#results)\n4. [Key Findings](#key-findings)\n5. [Comparison with SiT Results](#comparison-with-sit-results)\n6. [Future Directions](#future-directions)\n\n---\n\n## Introduction\n\n### The MOSTA Dataset\n\nThis analysis uses the [**MOSTA (Mouse Organogenesis Spatiotemporal Transcriptomic Atlas)** dataset](https://db.cngb.org/stomics/datasets/STDS0000058/summary), specifically the **E16.5_E1S1** section from [Chen et al., 2022](https://doi.org/10.1016/j.cell.2022.04.003). This dataset represents a significant scale-up from the SiT data:\n\n- **121,767 spatial spots** (47× larger than SiT)\n- **28,204 genes**, filtered to **3,000 highly variable genes (HVGs)**\n- **Spatial coordinates** capturing complex tissue architecture\n- **25 annotated tissue types/regions** including Brain, Liver, Heart, Kidney, Lung, Spinal cord, and diverse organ systems from developing mouse embryo\n\n![MOSTA Annotation](/projects/mosta_explore/mosta_anno.png)\n\n**Key Differences from SiT Study**:\n- **Scale**: ~50× more spots, enabling evaluation of scalability\n- **Complexity**: Multi-organ embryonic tissue vs. single brain region\n- **Heterogeneity**: 25 tissue types vs. 13 brain regions\n- **Biological Context**: Developmental biology vs. neuroanatomy\n\n**Research Question**: Do the patterns observed in small, single-tissue datasets generalize to large-scale, multi-organ spatial transcriptomics data? How do different SSL methods scale with data size and complexity?\n\n### Graph Construction\n\nFollowing the same approach as the [SiT analysis](/projects/gnn-ssl-sit), a **k-nearest neighbor spatial graph** (k=6) was constructed based on Euclidean distances between spot coordinates, resulting in **121,767 nodes** and **1,461,204 edges**.\n\n---\n\n## Methods\n\n### GNN Architectures\n\nThe same three GNN architectures were evaluated:\n\n1. **GraphSAGE (SAGEConv)**: Mean-pooling aggregation from sampled neighbors\n2. **Graph Attention Networks (GATConv)**: Learned attention weights (4 heads)\n3. **Graph Convolutional Networks (GCNConv)**: Spectral graph convolutions\n\n**Architecture specifications**:\n- 2 GNN layers\n- Hidden dimension: 256\n- Projection dimension: 64\n- Batch normalization and dropout (0.1)\n\n### Self-Supervised Learning Methods\n\nThe same eight SSL methods were compared: SimCLR, SwAV, BYOL, MoCo, SimSiam, MAE, Barlow Twins, and VICReg\n\n**Data Augmentation**: Gene dropout (10%) and Gaussian noise (scale=0.005)\n\n**Training**: 12 epochs (reduced from 20 due to dataset size; save time with limited computation resources), batch size 256, AdamW optimizer (lr=1e-4, weight decay=1e-5)\n\n### Evaluation Metrics\n\n**Clustering Metrics** (against 25 tissue annotations):\n- **AMI/NMI (Adjusted/Normalized Mutual Information)**: Agreement with annotations\n- **ARI (Adjusted Rand Index)**: Similarity between clusterings\n- **Silhouette Score**: Internal cluster quality\n\n**Spatial Metrics**:\n- **Moran's I**: Global spatial autocorrelation (higher = stronger spatial coherence)\n- **Geary's C**: Alternative spatial metric (lower = stronger coherence)\n\n---\n\n## Results\n\n### Clustering Visualizations by Backbone\n\nThe spatial clustering results show distinct patterns across GNN backbones and SSL methods:\n\n![SAGEConv Clustering Results](/projects/mosta_explore/SAGEConv.jpg)\n*Figure 1: Leiden clustering results for all SSL methods using SAGEConv backbone.*\n\n![GATConv Clustering Results](/projects/mosta_explore/GATConv.jpg)\n*Figure 2: Leiden clustering results for all SSL methods using GATConv backbone.*\n\n![GCNConv Clustering Results](/projects/mosta_explore/GCNConv.jpg)\n*Figure 3: Leiden clustering results for all SSL methods using GCNConv backbone.*\n\nNote: Some linear artifacts visible in plots are due to visualization rendering and do not reflect actual data structure.\n\n**Qualitative Observations**:\n- **SAGEConv** methods show sharp tissue boundaries with preserved local heterogeneity\n- **GATConv** methods exhibit balanced spatial coherence with attention-weighted aggregation\n- **GCNConv** methods demonstrate smoother boundaries but potential over-smoothing in complex regions\n- **MAE** consistently produces spatially coherent clusters across all backbones\n- **Contrastive methods** (SimCLR, MoCo) show more fragmented patterns, particularly with SAGEConv\n\n### Quantitative Performance Metrics\n\n![Method Comparison](/projects/mosta_explore/method_comparison.png)\n*Figure 4: Average performance by SSL method across all GNN backbones. Error bars show standard deviation across the three backbone architectures.*\n\n![Backbone Comparison](/projects/mosta_explore/backbone_comparison.png)\n*Figure 5: Average performance by GNN backbone across all SSL methods. Error bars show standard deviation across the eight SSL methods.*\n\n### Method Performance Summary\n\nAverage behavior across all three GNN backbones (mean ± std):\n\n| Method | AMI | NMI | ARI | Silhouette | Moran's I | Geary's C |\n|--------|---------|---------|---------|-------------|---------------|---------------|\n| **VICReg** | **0.655±0.025** | **0.656±0.025** | **0.452±0.059** | 0.269±0.057 | 0.942±0.036 | 0.056±0.035 |\n| **BarlowTwins** | **0.657±0.004** | **0.658±0.004** | **0.468±0.023** | 0.266±0.028 | 0.945±0.027 | 0.053±0.025 |\n| **MAE** | **0.650±0.032** | **0.650±0.032** | 0.441±0.061 | **0.317±0.007** | 0.936±0.021 | 0.062±0.021 |\n| SwAV | 0.649±0.002 | 0.649±0.002 | 0.443±0.013 | 0.243±0.027 | 0.944±0.025 | 0.054±0.024 |\n| BYOL | 0.637±0.011 | 0.637±0.011 | 0.425±0.010 | 0.247±0.007 | 0.936±0.032 | 0.062±0.032 |\n| MoCo | 0.610±0.014 | 0.611±0.014 | 0.440±0.033 | 0.108±0.009 | 0.886±0.041 | 0.112±0.041 |\n| SimCLR | 0.593±0.013 | 0.593±0.013 | 0.418±0.033 | 0.107±0.001 | 0.896±0.041 | 0.102±0.041 |\n| SimSiam | 0.591±0.049 | 0.591±0.049 | 0.387±0.063 | 0.308±0.007 | 0.942±0.029 | 0.058±0.031 |\n\n### Metric Relationships\n\n![Metric Scatter Plots](/projects/mosta_explore/metrics_scatterplots.png)\n*Figure 6: Relationships between different evaluation metrics. Strong positive correlation between AMI and Moran's I (ρ≈0.82) suggests methods that align well with tissue annotations also preserve spatial structure.*\n\n---\n\n## Key Findings\n\n### 1. Reconstruction-Based Approaches Excel at Scale\n\n**MAE's Surprising Performance**: Unlike in the [SiT study](/projects/gnn-ssl-sit) where MAE showed high silhouette scores but low clustering agreement (AMI=0.256), leaving the clustering quite noisy. MAE now achieves:\n- Competitive AMI (0.650±0.032), ranking 3rd among methods\n- **Highest silhouette scores** (0.317±0.007), indicating excellent internal cluster quality\n- Strong spatial coherence (Moran's I=0.936)\n- **2nd highest overall score** when paired with GATConv\n\n**Possible Explanations for Improved MAE Performance**:\n\n1. **Scale Effects**: With 121,767 spots vs. 2,560, the reconstruction task has substantially more signal to denoise\n   - Larger context neighborhoods provide more robust masking/reconstruction signals\n   - Averaging effects reduce the impact of stochastic noise in gene expression\n\n2. **Multi-Organ Diversity**: 25 tissue types with distinct expression signatures provide stronger reconstruction supervision\n   - Organ-specific gene programs create clearer reconstruction targets\n   - Developmental coherence (E16.5 embryo) ensures biological consistency\n\n3. **Improved Noise Robustness**: Large sample size allows the model to learn true signal vs. technical noise\n   - MAE's denoising objective becomes more effective with statistical power\n   - Over-smoothing less problematic when true biological variation is stronger\n\n### 2. Redundancy Reduction Methods Maintain Excellence\n\n**VICReg and Barlow Twins** continue to show top-tier performance:\n- **VICReg-SAGEConv**: Best overall performer (0.915 normalized score)\n- **Barlow Twins**: Most consistent across backbones (std=0.004 for AMI)\n- Both methods balance clustering quality, spatial coherence, and internal structure\n\nThis consistency across datasets (SiT and MOSTA) suggests redundancy reduction objectives are **robust to dataset scale and biological context**.\n\n### 3. Contrastive Methods Show Limitations at Scale\n\n**SimCLR and MoCo underperform** compared to smaller dataset:\n- Lowest AMI scores (0.593, 0.610 respectively)\n- Lowest silhouette scores (~0.11), suggesting poor internal cluster quality\n- High sensitivity to GNN backbone choice\n\n**Potential Issues**:\n1. **Hard Negative Sampling**: With 25 diverse tissue types, distinguishing true negatives becomes challenging (especially with the small batch size)\n2. **Temperature Sensitivity**: Fixed temperature (0.2) may not suit multi-organ diversity\n3. **Queue/Batch Size**: MoCo queue (4096) may not capture sufficient diversity\n4. **Augmentation Mismatch**: Gene dropout may be too aggressive for preserving tissue-specific signatures\n\n### 4. Momentum-Based Methods (BYOL) Show Stability\n\n**BYOL maintains consistent mid-tier performance**:\n- Stable across backbones (std=0.011 for AMI)\n- Balanced metrics without over-optimizing any single objective\n- No collapse issues despite lack of explicit negative pairs\n\n---\n\n## Comparison with SiT Results\n\n### Why MAE Performance Improved Dramatically\n\nThe **MAE paradox** from SiT (high silhouette, low AMI) completely reversed in MOSTA:\n\n**SiT (Small Dataset)**:\n- Reconstruction task may have learned technical noise\n- Limited biological variation for denoising supervision\n- Over-smoothed local brain region heterogeneity\n\n**MOSTA (Large Dataset)**:\n- Sufficient samples to separate signal from noise\n- Multi-organ diversity provides strong reconstruction signals\n- Embryonic developmental coherence aids structured learning\n\n**Implication**: Reconstruction-based SSL may be **highly scale-dependent**, requiring sufficient data to avoid overfitting to noise.\n\n### Consistency Across Datasets\n\n**Methods showing robust behavior**:\n1. **Barlow Twins**: Top performer in both datasets (low variance, high AMI)\n2. **VICReg**: Consistently excellent, especially with SAGEConv\n3. **BYOL**: Stable mid-tier performer regardless of scale\n\n**Methods sensitive to dataset characteristics**:\n1. **MAE**: Excellent on large/diverse data, poor on small/homogeneous data\n2. **SimCLR/MoCo**: Struggle with increased complexity\n3. **SimSiam**: High variance across datasets\n\n---\n\n## Future Directions\n\n### Critical Next Steps\n\n**1. Over-Smoothing Mitigation**\n\nGCNConv's poor performance highlights the need for advanced architectures:\n- **Global Spatial Attention**: Allow long-range dependencies beyond local neighborhoods\n  - Preliminary experiments with regional attention showed significant GAT improvements\n  - Positional encodings based on developmental axes (anterior-posterior, dorsal-ventral)\n- **Skip Connections**: Direct feature pathways to preserve local information\n- **Adaptive Aggregation**: Learn when to aggregate vs. preserve local features\n- **Graph Rewiring**: Dynamic edge updates based on learned feature similarity\n\n**2. Hyperparameter Optimization**\n\nCurrent parameters are only lightly tuned, leaving substantial room for improvement.\n\n**3. Better Evaluation Metrics**\n\nCurrent metrics have limitations:\n\n**Issues with AMI/NMI**:\n- Assume 25 annotations are ground truth (may be incomplete/subjective)\n- Don't capture biological interpretability\n- Biased toward majority classes (Brain: 17,374 spots vs. Adrenal: 194 spots)\n\n**Proposed Alternatives**:\n- **Gene Set Enrichment**: Do clusters enrich for known biological pathways?\n- **Marker Gene Recovery**: Can learned representations recover known tissue markers?\n- **Batch Effect Resilience**: Performance across multiple tissue sections/samples\n- **Transferability**: Fine-tuning efficiency on downstream tasks\n- **Biological Coherence**: Consistency with known developmental biology\n\n**4. Graph Construction Beyond k-NN**\n\nCurrent approach is purely geometric:\n- **Biological Graphs**: Edges based on gene expression similarity + spatial proximity\n- **Multi-modal Graphs**: Integrate protein/morphology if available\n- **Hierarchical Graphs**: Multiple scales (local neighborhoods + tissue-level regions)\n- **Developmental Axes**: Incorporate A-P, D-V, L-R axes for embryonic data\n\n**5. Novel Finding Discovery**\n\nContrastive methods learn discriminative features that may not align with current annotations:\n- **Unsupervised Discovery**: What novel patterns do SimCLR/MoCo learn?\n- **Transitional Zones**: Boundary regions between annotated tissues\n- **Rare Cellular States**: Sub-populations not captured in broad annotations\n- **Validation Strategy**: Compare with single-cell RNA-seq references, known developmental markers\n\n### Open Questions\n\n1. **Can embeddings from different methods be combined?**\n   - Ensemble approaches: average embeddings, late fusion, meta-learning\n   - Leverage complementary strengths (MAE's denoising + VICReg's structure)\n\n2. **Gene-centric vs. Spot-centric Learning**:\n   - Current: Each spot is a sample (spatial context)\n   - Alternative: Each gene is a sample (co-expression patterns across space)\n   - Which perspective better captures biological programs?\n\n---\n\n## Acknowledgments\n\nThis analysis leveraged:\n- **MOSTA dataset** \n- **PyTorch Geometric** for scalable GNN implementations\n- **Scanpy** for preprocessing and visualization\n- **Scikit-learn** for evaluation metrics\n- Previous framework established in [SiT exploration](/projects/gnn-ssl-sit)\n\n## References\n\n**SSL Methods**:\n- Chen et al. (2020) - SimCLR: A Simple Framework for Contrastive Learning\n- He et al. (2020) - MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\n- Grill et al. (2020) - BYOL: Bootstrap Your Own Latent\n- Caron et al. (2020) - SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\n- Chen & He (2021) - SimSiam: Exploring Simple Siamese Representation Learning\n- He et al. (2022) - MAE: Masked Autoencoders Are Scalable Vision Learners\n- Zbontar et al. (2021) - Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n- Bardes et al. (2022) - VICReg: Variance-Invariance-Covariance Regularization\n\n**GNN Architectures**:\n- Hamilton et al. (2017) - GraphSAGE: Inductive Representation Learning on Large Graphs\n- Veličković et al. (2018) - GAT: Graph Attention Networks\n- Kipf & Welling (2017) - GCN: Semi-Supervised Classification with Graph Convolutional Networks\n",
    "code": "var Component=(()=>{var g=Object.create;var s=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,v=Object.prototype.hasOwnProperty;var f=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),b=(i,e)=>{for(var r in e)s(i,r,{get:e[r],enumerable:!0})},a=(i,e,r,l)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let t of m(e))!v.call(i,t)&&t!==r&&s(i,t,{get:()=>e[t],enumerable:!(l=p(e,t))||l.enumerable});return i};var y=(i,e,r)=>(r=i!=null?g(u(i)):{},a(e||!i||!i.__esModule?s(r,\"default\",{value:i,enumerable:!0}):r,i)),S=i=>a(s({},\"__esModule\",{value:!0}),i);var o=f((A,c)=>{c.exports=_jsx_runtime});var N={};b(N,{default:()=>h,frontmatter:()=>w});var n=y(o()),w={title:\"Self-Supervised Learning Methods on Corss-tissye Spatial Transcriptomics Data (MOSTA)\",summary:\"Evaluating 8 SSL methods with 3 GNN architectures on large-scale mouse embryo spatial transcriptomics data reveals interesting performance of reconstruction-based approaches\",status:\"completed\",role:\"Research & Analysis\",stack:[\"PyTorch\",\"PyTorch Geometric\",\"Python\",\"Self-Supervised Learning\",\"Graph Neural Networks\",\"Spatial Transcriptomics\"],tags:[\"deep learning\",\"self-supervised learning\",\"bioinformatics\",\"spatial transcriptomics\",\"representation learning\",\"developmental biology\"],featured:!0,startDate:\"2025-9-30\"};function d(i){let e={a:\"a\",em:\"em\",h1:\"h1\",h2:\"h2\",h3:\"h3\",hr:\"hr\",img:\"img\",li:\"li\",ol:\"ol\",p:\"p\",span:\"span\",strong:\"strong\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",ul:\"ul\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h1,{id:\"self-supervised-learning-methods-on-corss-tissye-spatial-transcriptomics-data-mosta\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#self-supervised-learning-methods-on-corss-tissye-spatial-transcriptomics-data-mosta\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Self-Supervised Learning Methods on Corss-tissye Spatial Transcriptomics Data (MOSTA)\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Building on the \",(0,n.jsx)(e.a,{href:\"/projects/gnn-ssl-sit\",children:\"previous exploration with SiT mouse brain data\"}),\", this study evaluates the same self-supervised learning framework on a substantially larger and more complex dataset to assess scalability, cross-tissue generalizability, and method robustness.\"]}),`\n`,(0,n.jsxs)(e.h2,{id:\"table-of-contents\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#table-of-contents\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Table of Contents\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#introduction\",children:\"Introduction\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#methods\",children:\"Methods\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#results\",children:\"Results\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#key-findings\",children:\"Key Findings\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#comparison-with-sit-results\",children:\"Comparison with SiT Results\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#future-directions\",children:\"Future Directions\"})}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"introduction\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#introduction\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Introduction\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"the-mosta-dataset\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#the-mosta-dataset\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"The MOSTA Dataset\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"This analysis uses the \",(0,n.jsxs)(e.a,{href:\"https://db.cngb.org/stomics/datasets/STDS0000058/summary\",children:[(0,n.jsx)(e.strong,{children:\"MOSTA (Mouse Organogenesis Spatiotemporal Transcriptomic Atlas)\"}),\" dataset\"]}),\", specifically the \",(0,n.jsx)(e.strong,{children:\"E16.5_E1S1\"}),\" section from \",(0,n.jsx)(e.a,{href:\"https://doi.org/10.1016/j.cell.2022.04.003\",children:\"Chen et al., 2022\"}),\". This dataset represents a significant scale-up from the SiT data:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"121,767 spatial spots\"}),\" (47\\xD7 larger than SiT)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"28,204 genes\"}),\", filtered to \",(0,n.jsx)(e.strong,{children:\"3,000 highly variable genes (HVGs)\"})]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Spatial coordinates\"}),\" capturing complex tissue architecture\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"25 annotated tissue types/regions\"}),\" including Brain, Liver, Heart, Kidney, Lung, Spinal cord, and diverse organ systems from developing mouse embryo\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/mosta_anno.png\",alt:\"MOSTA Annotation\"})}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Key Differences from SiT Study\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Scale\"}),\": ~50\\xD7 more spots, enabling evaluation of scalability\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Complexity\"}),\": Multi-organ embryonic tissue vs. single brain region\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Heterogeneity\"}),\": 25 tissue types vs. 13 brain regions\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Biological Context\"}),\": Developmental biology vs. neuroanatomy\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Research Question\"}),\": Do the patterns observed in small, single-tissue datasets generalize to large-scale, multi-organ spatial transcriptomics data? How do different SSL methods scale with data size and complexity?\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"graph-construction\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#graph-construction\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Graph Construction\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Following the same approach as the \",(0,n.jsx)(e.a,{href:\"/projects/gnn-ssl-sit\",children:\"SiT analysis\"}),\", a \",(0,n.jsx)(e.strong,{children:\"k-nearest neighbor spatial graph\"}),\" (k=6) was constructed based on Euclidean distances between spot coordinates, resulting in \",(0,n.jsx)(e.strong,{children:\"121,767 nodes\"}),\" and \",(0,n.jsx)(e.strong,{children:\"1,461,204 edges\"}),\".\"]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"methods\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#methods\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Methods\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"gnn-architectures\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#gnn-architectures\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"GNN Architectures\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The same three GNN architectures were evaluated:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"GraphSAGE (SAGEConv)\"}),\": Mean-pooling aggregation from sampled neighbors\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Graph Attention Networks (GATConv)\"}),\": Learned attention weights (4 heads)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Graph Convolutional Networks (GCNConv)\"}),\": Spectral graph convolutions\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Architecture specifications\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"2 GNN layers\"}),`\n`,(0,n.jsx)(e.li,{children:\"Hidden dimension: 256\"}),`\n`,(0,n.jsx)(e.li,{children:\"Projection dimension: 64\"}),`\n`,(0,n.jsx)(e.li,{children:\"Batch normalization and dropout (0.1)\"}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"self-supervised-learning-methods\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#self-supervised-learning-methods\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Self-Supervised Learning Methods\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The same eight SSL methods were compared: SimCLR, SwAV, BYOL, MoCo, SimSiam, MAE, Barlow Twins, and VICReg\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Data Augmentation\"}),\": Gene dropout (10%) and Gaussian noise (scale=0.005)\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Training\"}),\": 12 epochs (reduced from 20 due to dataset size; save time with limited computation resources), batch size 256, AdamW optimizer (lr=1e-4, weight decay=1e-5)\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"evaluation-metrics\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#evaluation-metrics\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Evaluation Metrics\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Clustering Metrics\"}),\" (against 25 tissue annotations):\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"AMI/NMI (Adjusted/Normalized Mutual Information)\"}),\": Agreement with annotations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"ARI (Adjusted Rand Index)\"}),\": Similarity between clusterings\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Silhouette Score\"}),\": Internal cluster quality\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Spatial Metrics\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Moran's I\"}),\": Global spatial autocorrelation (higher = stronger spatial coherence)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Geary's C\"}),\": Alternative spatial metric (lower = stronger coherence)\"]}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"results\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#results\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Results\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"clustering-visualizations-by-backbone\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#clustering-visualizations-by-backbone\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Clustering Visualizations by Backbone\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The spatial clustering results show distinct patterns across GNN backbones and SSL methods:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/SAGEConv.jpg\",alt:\"SAGEConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 1: Leiden clustering results for all SSL methods using SAGEConv backbone.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/GATConv.jpg\",alt:\"GATConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 2: Leiden clustering results for all SSL methods using GATConv backbone.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/GCNConv.jpg\",alt:\"GCNConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 3: Leiden clustering results for all SSL methods using GCNConv backbone.\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"Note: Some linear artifacts visible in plots are due to visualization rendering and do not reflect actual data structure.\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Qualitative Observations\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SAGEConv\"}),\" methods show sharp tissue boundaries with preserved local heterogeneity\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"GATConv\"}),\" methods exhibit balanced spatial coherence with attention-weighted aggregation\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"GCNConv\"}),\" methods demonstrate smoother boundaries but potential over-smoothing in complex regions\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"MAE\"}),\" consistently produces spatially coherent clusters across all backbones\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Contrastive methods\"}),\" (SimCLR, MoCo) show more fragmented patterns, particularly with SAGEConv\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"quantitative-performance-metrics\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#quantitative-performance-metrics\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Quantitative Performance Metrics\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/method_comparison.png\",alt:\"Method Comparison\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 4: Average performance by SSL method across all GNN backbones. Error bars show standard deviation across the three backbone architectures.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/backbone_comparison.png\",alt:\"Backbone Comparison\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 5: Average performance by GNN backbone across all SSL methods. Error bars show standard deviation across the eight SSL methods.\"})]}),`\n`,(0,n.jsxs)(e.h3,{id:\"method-performance-summary\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#method-performance-summary\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Method Performance Summary\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Average behavior across all three GNN backbones (mean \\xB1 std):\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Method\"}),(0,n.jsx)(e.th,{children:\"AMI\"}),(0,n.jsx)(e.th,{children:\"NMI\"}),(0,n.jsx)(e.th,{children:\"ARI\"}),(0,n.jsx)(e.th,{children:\"Silhouette\"}),(0,n.jsx)(e.th,{children:\"Moran's I\"}),(0,n.jsx)(e.th,{children:\"Geary's C\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"VICReg\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.655\\xB10.025\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.656\\xB10.025\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.452\\xB10.059\"})}),(0,n.jsx)(e.td,{children:\"0.269\\xB10.057\"}),(0,n.jsx)(e.td,{children:\"0.942\\xB10.036\"}),(0,n.jsx)(e.td,{children:\"0.056\\xB10.035\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"BarlowTwins\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.657\\xB10.004\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.658\\xB10.004\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.468\\xB10.023\"})}),(0,n.jsx)(e.td,{children:\"0.266\\xB10.028\"}),(0,n.jsx)(e.td,{children:\"0.945\\xB10.027\"}),(0,n.jsx)(e.td,{children:\"0.053\\xB10.025\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"MAE\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.650\\xB10.032\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.650\\xB10.032\"})}),(0,n.jsx)(e.td,{children:\"0.441\\xB10.061\"}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.317\\xB10.007\"})}),(0,n.jsx)(e.td,{children:\"0.936\\xB10.021\"}),(0,n.jsx)(e.td,{children:\"0.062\\xB10.021\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SwAV\"}),(0,n.jsx)(e.td,{children:\"0.649\\xB10.002\"}),(0,n.jsx)(e.td,{children:\"0.649\\xB10.002\"}),(0,n.jsx)(e.td,{children:\"0.443\\xB10.013\"}),(0,n.jsx)(e.td,{children:\"0.243\\xB10.027\"}),(0,n.jsx)(e.td,{children:\"0.944\\xB10.025\"}),(0,n.jsx)(e.td,{children:\"0.054\\xB10.024\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"BYOL\"}),(0,n.jsx)(e.td,{children:\"0.637\\xB10.011\"}),(0,n.jsx)(e.td,{children:\"0.637\\xB10.011\"}),(0,n.jsx)(e.td,{children:\"0.425\\xB10.010\"}),(0,n.jsx)(e.td,{children:\"0.247\\xB10.007\"}),(0,n.jsx)(e.td,{children:\"0.936\\xB10.032\"}),(0,n.jsx)(e.td,{children:\"0.062\\xB10.032\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"MoCo\"}),(0,n.jsx)(e.td,{children:\"0.610\\xB10.014\"}),(0,n.jsx)(e.td,{children:\"0.611\\xB10.014\"}),(0,n.jsx)(e.td,{children:\"0.440\\xB10.033\"}),(0,n.jsx)(e.td,{children:\"0.108\\xB10.009\"}),(0,n.jsx)(e.td,{children:\"0.886\\xB10.041\"}),(0,n.jsx)(e.td,{children:\"0.112\\xB10.041\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SimCLR\"}),(0,n.jsx)(e.td,{children:\"0.593\\xB10.013\"}),(0,n.jsx)(e.td,{children:\"0.593\\xB10.013\"}),(0,n.jsx)(e.td,{children:\"0.418\\xB10.033\"}),(0,n.jsx)(e.td,{children:\"0.107\\xB10.001\"}),(0,n.jsx)(e.td,{children:\"0.896\\xB10.041\"}),(0,n.jsx)(e.td,{children:\"0.102\\xB10.041\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SimSiam\"}),(0,n.jsx)(e.td,{children:\"0.591\\xB10.049\"}),(0,n.jsx)(e.td,{children:\"0.591\\xB10.049\"}),(0,n.jsx)(e.td,{children:\"0.387\\xB10.063\"}),(0,n.jsx)(e.td,{children:\"0.308\\xB10.007\"}),(0,n.jsx)(e.td,{children:\"0.942\\xB10.029\"}),(0,n.jsx)(e.td,{children:\"0.058\\xB10.031\"})]})]})]}),`\n`,(0,n.jsxs)(e.h3,{id:\"metric-relationships\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#metric-relationships\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Metric Relationships\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/mosta_explore/metrics_scatterplots.png\",alt:\"Metric Scatter Plots\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 6: Relationships between different evaluation metrics. Strong positive correlation between AMI and Moran's I (\\u03C1\\u22480.82) suggests methods that align well with tissue annotations also preserve spatial structure.\"})]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"key-findings\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#key-findings\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Key Findings\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"1-reconstruction-based-approaches-excel-at-scale\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#1-reconstruction-based-approaches-excel-at-scale\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"1. Reconstruction-Based Approaches Excel at Scale\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"MAE's Surprising Performance\"}),\": Unlike in the \",(0,n.jsx)(e.a,{href:\"/projects/gnn-ssl-sit\",children:\"SiT study\"}),\" where MAE showed high silhouette scores but low clustering agreement (AMI=0.256), leaving the clustering quite noisy. MAE now achieves:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Competitive AMI (0.650\\xB10.032), ranking 3rd among methods\"}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Highest silhouette scores\"}),\" (0.317\\xB10.007), indicating excellent internal cluster quality\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Strong spatial coherence (Moran's I=0.936)\"}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"2nd highest overall score\"}),\" when paired with GATConv\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Possible Explanations for Improved MAE Performance\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Scale Effects\"}),\": With 121,767 spots vs. 2,560, the reconstruction task has substantially more signal to denoise\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Larger context neighborhoods provide more robust masking/reconstruction signals\"}),`\n`,(0,n.jsx)(e.li,{children:\"Averaging effects reduce the impact of stochastic noise in gene expression\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Multi-Organ Diversity\"}),\": 25 tissue types with distinct expression signatures provide stronger reconstruction supervision\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Organ-specific gene programs create clearer reconstruction targets\"}),`\n`,(0,n.jsx)(e.li,{children:\"Developmental coherence (E16.5 embryo) ensures biological consistency\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Improved Noise Robustness\"}),\": Large sample size allows the model to learn true signal vs. technical noise\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"MAE's denoising objective becomes more effective with statistical power\"}),`\n`,(0,n.jsx)(e.li,{children:\"Over-smoothing less problematic when true biological variation is stronger\"}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"2-redundancy-reduction-methods-maintain-excellence\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#2-redundancy-reduction-methods-maintain-excellence\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"2. Redundancy Reduction Methods Maintain Excellence\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"VICReg and Barlow Twins\"}),\" continue to show top-tier performance:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"VICReg-SAGEConv\"}),\": Best overall performer (0.915 normalized score)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Barlow Twins\"}),\": Most consistent across backbones (std=0.004 for AMI)\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Both methods balance clustering quality, spatial coherence, and internal structure\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"This consistency across datasets (SiT and MOSTA) suggests redundancy reduction objectives are \",(0,n.jsx)(e.strong,{children:\"robust to dataset scale and biological context\"}),\".\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"3-contrastive-methods-show-limitations-at-scale\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#3-contrastive-methods-show-limitations-at-scale\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"3. Contrastive Methods Show Limitations at Scale\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SimCLR and MoCo underperform\"}),\" compared to smaller dataset:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Lowest AMI scores (0.593, 0.610 respectively)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Lowest silhouette scores (~0.11), suggesting poor internal cluster quality\"}),`\n`,(0,n.jsx)(e.li,{children:\"High sensitivity to GNN backbone choice\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Potential Issues\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Hard Negative Sampling\"}),\": With 25 diverse tissue types, distinguishing true negatives becomes challenging (especially with the small batch size)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Temperature Sensitivity\"}),\": Fixed temperature (0.2) may not suit multi-organ diversity\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Queue/Batch Size\"}),\": MoCo queue (4096) may not capture sufficient diversity\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Augmentation Mismatch\"}),\": Gene dropout may be too aggressive for preserving tissue-specific signatures\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"4-momentum-based-methods-byol-show-stability\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#4-momentum-based-methods-byol-show-stability\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"4. Momentum-Based Methods (BYOL) Show Stability\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"BYOL maintains consistent mid-tier performance\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Stable across backbones (std=0.011 for AMI)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Balanced metrics without over-optimizing any single objective\"}),`\n`,(0,n.jsx)(e.li,{children:\"No collapse issues despite lack of explicit negative pairs\"}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"comparison-with-sit-results\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#comparison-with-sit-results\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Comparison with SiT Results\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"why-mae-performance-improved-dramatically\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#why-mae-performance-improved-dramatically\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Why MAE Performance Improved Dramatically\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"The \",(0,n.jsx)(e.strong,{children:\"MAE paradox\"}),\" from SiT (high silhouette, low AMI) completely reversed in MOSTA:\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SiT (Small Dataset)\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Reconstruction task may have learned technical noise\"}),`\n`,(0,n.jsx)(e.li,{children:\"Limited biological variation for denoising supervision\"}),`\n`,(0,n.jsx)(e.li,{children:\"Over-smoothed local brain region heterogeneity\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"MOSTA (Large Dataset)\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Sufficient samples to separate signal from noise\"}),`\n`,(0,n.jsx)(e.li,{children:\"Multi-organ diversity provides strong reconstruction signals\"}),`\n`,(0,n.jsx)(e.li,{children:\"Embryonic developmental coherence aids structured learning\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Implication\"}),\": Reconstruction-based SSL may be \",(0,n.jsx)(e.strong,{children:\"highly scale-dependent\"}),\", requiring sufficient data to avoid overfitting to noise.\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"consistency-across-datasets\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#consistency-across-datasets\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Consistency Across Datasets\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Methods showing robust behavior\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Barlow Twins\"}),\": Top performer in both datasets (low variance, high AMI)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"VICReg\"}),\": Consistently excellent, especially with SAGEConv\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"BYOL\"}),\": Stable mid-tier performer regardless of scale\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Methods sensitive to dataset characteristics\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"MAE\"}),\": Excellent on large/diverse data, poor on small/homogeneous data\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SimCLR/MoCo\"}),\": Struggle with increased complexity\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SimSiam\"}),\": High variance across datasets\"]}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"future-directions\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#future-directions\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Future Directions\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"critical-next-steps\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#critical-next-steps\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Critical Next Steps\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"1. Over-Smoothing Mitigation\"})}),`\n`,(0,n.jsx)(e.p,{children:\"GCNConv's poor performance highlights the need for advanced architectures:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Global Spatial Attention\"}),\": Allow long-range dependencies beyond local neighborhoods\",`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Preliminary experiments with regional attention showed significant GAT improvements\"}),`\n`,(0,n.jsx)(e.li,{children:\"Positional encodings based on developmental axes (anterior-posterior, dorsal-ventral)\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Skip Connections\"}),\": Direct feature pathways to preserve local information\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Adaptive Aggregation\"}),\": Learn when to aggregate vs. preserve local features\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Graph Rewiring\"}),\": Dynamic edge updates based on learned feature similarity\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"2. Hyperparameter Optimization\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Current parameters are only lightly tuned, leaving substantial room for improvement.\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"3. Better Evaluation Metrics\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Current metrics have limitations:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Issues with AMI/NMI\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Assume 25 annotations are ground truth (may be incomplete/subjective)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Don't capture biological interpretability\"}),`\n`,(0,n.jsx)(e.li,{children:\"Biased toward majority classes (Brain: 17,374 spots vs. Adrenal: 194 spots)\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Proposed Alternatives\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Gene Set Enrichment\"}),\": Do clusters enrich for known biological pathways?\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Marker Gene Recovery\"}),\": Can learned representations recover known tissue markers?\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Batch Effect Resilience\"}),\": Performance across multiple tissue sections/samples\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Transferability\"}),\": Fine-tuning efficiency on downstream tasks\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Biological Coherence\"}),\": Consistency with known developmental biology\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"4. Graph Construction Beyond k-NN\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Current approach is purely geometric:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Biological Graphs\"}),\": Edges based on gene expression similarity + spatial proximity\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Multi-modal Graphs\"}),\": Integrate protein/morphology if available\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Hierarchical Graphs\"}),\": Multiple scales (local neighborhoods + tissue-level regions)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Developmental Axes\"}),\": Incorporate A-P, D-V, L-R axes for embryonic data\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"5. Novel Finding Discovery\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Contrastive methods learn discriminative features that may not align with current annotations:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Unsupervised Discovery\"}),\": What novel patterns do SimCLR/MoCo learn?\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Transitional Zones\"}),\": Boundary regions between annotated tissues\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Rare Cellular States\"}),\": Sub-populations not captured in broad annotations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Validation Strategy\"}),\": Compare with single-cell RNA-seq references, known developmental markers\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"open-questions\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#open-questions\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Open Questions\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.strong,{children:\"Can embeddings from different methods be combined?\"})}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Ensemble approaches: average embeddings, late fusion, meta-learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"Leverage complementary strengths (MAE's denoising + VICReg's structure)\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Gene-centric vs. Spot-centric Learning\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Current: Each spot is a sample (spatial context)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Alternative: Each gene is a sample (co-expression patterns across space)\"}),`\n`,(0,n.jsx)(e.li,{children:\"Which perspective better captures biological programs?\"}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"acknowledgments\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#acknowledgments\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Acknowledgments\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This analysis leveraged:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.strong,{children:\"MOSTA dataset\"})}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"PyTorch Geometric\"}),\" for scalable GNN implementations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Scanpy\"}),\" for preprocessing and visualization\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Scikit-learn\"}),\" for evaluation metrics\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"Previous framework established in \",(0,n.jsx)(e.a,{href:\"/projects/gnn-ssl-sit\",children:\"SiT exploration\"})]}),`\n`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"references\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#references\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"References\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SSL Methods\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Chen et al. (2020) - SimCLR: A Simple Framework for Contrastive Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"He et al. (2020) - MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"Grill et al. (2020) - BYOL: Bootstrap Your Own Latent\"}),`\n`,(0,n.jsx)(e.li,{children:\"Caron et al. (2020) - SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\"}),`\n`,(0,n.jsx)(e.li,{children:\"Chen & He (2021) - SimSiam: Exploring Simple Siamese Representation Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"He et al. (2022) - MAE: Masked Autoencoders Are Scalable Vision Learners\"}),`\n`,(0,n.jsx)(e.li,{children:\"Zbontar et al. (2021) - Barlow Twins: Self-Supervised Learning via Redundancy Reduction\"}),`\n`,(0,n.jsx)(e.li,{children:\"Bardes et al. (2022) - VICReg: Variance-Invariance-Covariance Regularization\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"GNN Architectures\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Hamilton et al. (2017) - GraphSAGE: Inductive Representation Learning on Large Graphs\"}),`\n`,(0,n.jsx)(e.li,{children:\"Veli\\u010Dkovi\\u0107 et al. (2018) - GAT: Graph Attention Networks\"}),`\n`,(0,n.jsx)(e.li,{children:\"Kipf & Welling (2017) - GCN: Semi-Supervised Classification with Graph Convolutional Networks\"}),`\n`]})]})}function h(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(d,{...i})}):d(i)}return S(N);})();\n;return Component;"
  },
  "_id": "projects/gnn-ssl-mosta.mdx",
  "_raw": {
    "sourceFilePath": "projects/gnn-ssl-mosta.mdx",
    "sourceFileName": "gnn-ssl-mosta.mdx",
    "sourceFileDir": "projects",
    "contentType": "mdx",
    "flattenedPath": "projects/gnn-ssl-mosta"
  },
  "type": "Project",
  "url": "/projects/gnn-ssl-mosta",
  "slug": "gnn-ssl-mosta"
}