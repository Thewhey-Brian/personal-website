{
  "title": "Comparing Self-Supervised Learning Methods for Spatial Transcriptomics",
  "summary": "A systematic evaluation of 8 SSL methods with 3 GNN architectures on mouse brain spatial transcriptomics data",
  "status": "completed",
  "role": "Research & Analysis",
  "stack": [
    "PyTorch",
    "PyTorch Geometric",
    "Python",
    "Self-Supervised Learning",
    "Graph Neural Networks",
    "Spatial Transcriptomics"
  ],
  "images": [],
  "tags": [
    "deep learning",
    "self-supervised learning",
    "bioinformatics",
    "spatial transcriptomics",
    "representation learning"
  ],
  "featured": true,
  "startDate": "2025-09-16T00:00:00.000Z",
  "body": {
    "raw": "\n# Comparing Self-Supervised Learning Methods for Spatial Transcriptomics\n\nA systematic evaluation exploring how different self-supervised learning approaches perform when combined with graph neural networks for learning spatial transcriptomics representations.\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Methods](#methods)\n3. [Results](#results)\n4. [Key Findings](#key-findings)\n5. [Future Directions](#future-directions)\n\n---\n\n## Introduction\n\n### The Data and Problem\n\nAnalyzed spatial transcriptomics data from the **SiT Mouse Brain dataset** (CBS1_illu) by [Lebrigand et al., 2023](https://doi.org/10.1093/nar/gkad169), which captures gene expression patterns with spatial context from mouse brain samples. The dataset comprises:\n\n- **2,560 spatial spots** representing distinct tissue locations\n- **31,053 genes**, filtered to **3,000 highly variable genes (HVGs)**\n- **Spatial coordinates** preserving tissue architecture\n- **13 annotated cell types/regions** including CA1/CA2, CA3, DG, Hippocampus, Hypothalamus, Isocortex, and others\n\n![SiT CBS1_illu_anno](/projects/sit_explore/CBS1_anno.jpg)\n\n**Research Question**: How do different self-supervised learning (SSL) approaches perform when combined with graph neural networks (GNNs) for learning spatial transcriptomics representations?\n\n### Graph Construction\n\nAs detailed in my [previous work on GNNs for spatial transcriptomics](/projects/gnn-spatial-transcriptomics), I constructed a **k-nearest neighbor spatial graph** (k=8) based on Euclidean distances between spot coordinates, resulting in **2,560 nodes** and **40,960 edges**.\n\n---\n\n## Methods\n\n### GNN Architectures\n\nThree GNN architectures were evaluated as encoder backbones:\n\n1. **GraphSAGE (SAGEConv)**: Samples and aggregates features from neighbors using mean pooling\n2. **Graph Attention Networks (GATConv)**: Learns attention weights to weigh neighbor importance (4 attention heads)\n3. **Graph Convolutional Networks (GCNConv)**: Applies spectral graph convolutions for feature aggregation\n\n**Architecture specifications**:\n- 2 GNN layers\n- Hidden dimension: 256\n- Projection dimension: 64\n- Batch normalization and dropout (0.1) between layers\n\n### Self-Supervised Learning Methods\n\nEight state-of-the-art SSL methods were compared across different families:\n\n**Contrastive Learning**:\n- **SimCLR**: Contrastive learning using NT-Xent loss (temperature=0.2)\n- **SwAV**: Swapping assignments between views using optimal transport (512 prototypes)\n\n**Momentum-based Methods**:\n- **BYOL**: Bootstrap Your Own Latent without negative pairs (momentum=0.99)\n- **MoCo**: Momentum contrast with a queue of negative samples (queue size=4096, momentum=0.99)\n- **SimSiam**: Simple Siamese Networks with stop-gradient\n\n**Reconstruction-based**:\n- **MAE**: Masked Autoencoder reconstructing masked gene expressions (mask ratio=0.75)\n\n**Redundancy Reduction**:\n- **Barlow Twins**: Self-supervised learning via redundancy reduction (λ=0.005)\n- **VICReg**: Variance-Invariance-Covariance Regularization (λ_inv=25, λ_var=25, λ_cov=1)\n\n**Data Augmentation**: Gene dropout (10%) and Gaussian noise addition (scale=0.005)\n\n**Training**: 20 epochs, batch size 256, AdamW optimizer (lr=1e-4, weight decay=1e-5)\n\n### Evaluation Metrics\n\nFive complementary metrics were used to evaluate **24 method-backbone combinations**:\n\n- **AMI/NMI (Adjusted/Normalized Mutual Information)**: Clustering agreement with ground truth annotations\n- **Silhouette Score**: Internal cluster cohesion and separation\n- **Moran's I**: Global spatial autocorrelation (higher = stronger spatial coherence)\n- **Geary's C**: Alternative spatial autocorrelation measure (lower = stronger spatial coherence)\n\n**Important Note**: These metrics provide a **partial view** of model performance. They don't capture robustness to batch effects, transferability to downstream tasks, biological interpretability, or performance on rare cell types.\n\n---\n\n## Results\n\n### Clustering Visualizations by Backbone\n\nThe spatial clustering results reveal substantial qualitative differences across methods and backbones:\n\n![SAGEConv Clustering Results](/projects/sit_explore/SAGEConv.jpg)\n*Figure 1: Leiden clustering results for all SSL methods using SAGEConv backbone. SAGEConv-based methods tend to produce more fragmented spatial patterns with sharper local transitions, potentially preserving fine-grained local heterogeneity.*\n\n![GATConv Clustering Results](/projects/sit_explore/GATConc.jpg)\n*Figure 2: Leiden clustering results for all SSL methods using GATConv backbone. GATConv shows intermediate behavior with learned attention weights adding flexibility to adapt to local structure.*\n\n![GCNConv Clustering Results](/projects/sit_explore/GCNConv.jpg)\n*Figure 3: Leiden clustering results for all SSL methods using GCNConv backbone. GCNConv-based methods generally show more spatially contiguous clusters with smoother boundaries and stronger delineation along major anatomical boundaries.*\n\n### Quantitative Performance Metrics\n\n![Method Comparison](/projects/sit_explore/method_comparison.png)\n*Figure 4: Average performance by SSL method across clustering and spatial metrics. Redundancy reduction methods (VICReg, Barlow Twins) show higher clustering agreement, while methods vary substantially in spatial autocorrelation.*\n\n![Backbone Comparison](/projects/sit_explore/backbone_comparison.png)\n*Figure 5: Average performance by GNN backbone. GCNConv shows very low variance in spatial metrics, suggesting strong spatial smoothing. SAGEConv exhibits highest variance across methods, indicating SSL objective matters more for this backbone.*\n\n### Method Performance Summary\n\nAverage behavior across all three GNN backbones (mean ± std):\n\n| Method | AMI | NMI | Silhouette | Moran's I | Geary's C |\n|--------|---------|---------|----------------|---------------|---------------|\n| VICReg | 0.566±0.095 | 0.572±0.094 | 0.283±0.023 | 0.847±0.072 | 0.153±0.070 |\n| Barlow Twins | 0.558±0.036 | 0.563±0.036 | 0.266±0.024 | 0.855±0.092 | 0.145±0.091 |\n| SwAV | 0.529±0.047 | 0.536±0.046 | 0.269±0.042 | 0.830±0.108 | 0.172±0.106 |\n| **BYOL** | **0.524±0.023** | **0.531±0.023** | **0.271±0.027** | **0.819±0.121** | **0.184±0.116** |\n| MoCo | 0.515±0.067 | 0.522±0.066 | 0.184±0.027 | 0.781±0.151 | 0.224±0.148 |\n| SimCLR | 0.506±0.022 | 0.513±0.022 | 0.186±0.033 | 0.791±0.130 | 0.210±0.129 |\n| SimSiam | 0.479±0.016 | 0.486±0.016 | 0.247±0.018 | 0.809±0.120 | 0.187±0.119 |\n| MAE | 0.256±0.018 | 0.265±0.018 | 0.328±0.006 | 0.806±0.097 | 0.189±0.096 |\n\n### Metric Relationships\n\n![Metric Scatter Plots](/projects/sit_explore/metrics_scatterplots.png)\n*Figure 6: Relationships between clustering quality and spatial coherence metrics. AMI vs. Moran's I show positive correlation (ρ≈0.75), though this may reflect GCNConv's strong influence on both metrics.*\n\n---\n\n## Key Findings\n\n### Observed Patterns\n\n**BYOL with SAGEConv shows promise**: This combination achieves balanced performance across metrics (AMI=0.510, NMI=0.516, Silhouette=0.254, Moran's I=0.683) without over-optimizing for any single one, suggesting potential for further investigation.\n\n**Redundancy reduction methods show consistency**: VICReg and Barlow Twins exhibit higher AMI/NMI values and more consistent behavior across backbones (lower std), suggesting robust learning dynamics.\n\n**BYOL demonstrates remarkable consistency**: With std=0.023 for AMI across different GNN architectures, BYOL's momentum-based approach appears robust to architectural choices.\n\n**MAE exhibits a paradox**: Highest Silhouette scores (0.328) but lowest clustering agreement (AMI=0.256). This suggests it learns internally coherent representations that don't align with the provided annotations. It maybe suffering from the \"noise\"?\n\n**Strong method-backbone interactions**: The same SSL method behaves very differently depending on GNN backbone, with variance up to 0.124 in AMI, indicating that architecture choice significantly influences representation learning.\n\n### GNN Backbone Trade-offs\n\n**GCNConv**: Shows very low variance in spatial metrics (std=0.007 for Moran's I), suggesting spectral operations impose strong spatial smoothing regardless of SSL method. This high spatial coherence may be desirable or may indicate over-smoothing.\n\n**SAGEConv**: Exhibits comparable AMI to GCNConv (0.510 vs. 0.507) but lower spatial autocorrelation (Moran's I=0.695). **Highest variance across methods** (std=0.124) indicates SSL objective matters more for this backbone, potentially preserving local heterogeneity (can also be observed from Figure 1~3).\n\n**GATConv**: Shows intermediate values across all metrics with learned attention weights providing flexibility to adapt to local structure. As a side project, I experimented with adding regional attention mechanisms that provide the model with global spatial relationships, which significantly improved GAT's performance across all metrics.\n\n---\n\n## Key Findings\n\n### Critical Limitations\n\nThis exploratory study has important limitations that constrain conclusions:\n\n**Evaluation Limitations**:\n- Metrics are proxies, not ground truth—AMI/NMI assume the 13 annotated regions are \"correct,\" but annotations may be incomplete or subjective\n- Single dataset from mouse brain may not generalize to other tissues or organisms\n- Limited hyperparameter exploration (only 20 epochs, fixed augmentation parameters)\n- No downstream task evaluation for actual biological utility\n- Small dataset (2,560 spots) may not reveal scalability issues\n\n**Interpretation Challenges**: High Moran's I could reflect beneficial spatial structure or excessive smoothing. High Silhouette doesn't guarantee biological relevance. Therefore, these metrics primarily identify differences in learned representations rather than definitively ranking method quality.\n\n### Potential Hybrid Approaches\n\nGiven different strengths of each method family, combining approaches may be promising:\n\n**SimCLR + Barlow Twins**: Combine discriminative learning through contrastive loss with decorrelation to prevent feature redundancy. This may achieve both strong discrimination and feature diversity without collapse.\n\n**BYOL + VICReg**: Add VICReg's variance/covariance terms to BYOL's predictor objective to provide explicit collapse prevention mechanism while maintaining momentum-based stability.\n\n**Spatial-aware SSL**: Add explicit spatial regularization term to existing methods to test whether explicit spatial terms improve over implicit (GNN-based) spatial encoding.\n\n---\n\n## Future Directions\n\n### Next Steps\n\n**Cross-tissue validation**: The single-dataset limitation is this study's most critical weakness. Evaluation on diverse tissues (liver, heart, tumor microenvironments) and larger datasets (10,000+ spots) is essential to assess generalizability and scalability.\n\n**Biological validation**: Beyond clustering metrics, I plan to evaluate differential gene expression, pathway enrichment, rare cell type recovery, and spatial trajectory inference quality to assess actual biological utility.\n\n**Hybrid method development**: Systematic investigation of combined approaches (SimCLR+Barlow Twins, BYOL+VICReg) with careful hyperparameter tuning may leverage complementary strengths.\n\n**Downstream task evaluation**: Test representations on actual biological questions including differential expression analysis, cell-cell communication, and trajectory inference.\n\n### Open Questions\n\n1. Why does BYOL-SAGEConv show such balanced behavior across metrics?\n2. Can we design metrics that better reflect biological utility rather than statistical properties?\n3. How do methods perform on rare cell types not well-represented in the dataset?\n4. What is the minimal dataset size needed for each method to perform effectively?\n5. Can we predict which method suits a given tissue type a priori?\n6. Can we treat gene expression patterns as samples instead of spots? Currently, each spot (with its gene expression vector) is treated as a sample. An alternative approach would be to treat each gene's expression pattern across all spots as a sample—essentially viewing each gene as an \"image\" where pixel intensities represent expression levels at different spatial locations. This gene-centric perspective might reveal different biological insights about co-expression patterns and spatial gene regulatory networks.\n\n---\n\n## Conclusion\n\nThis systematic comparison of 8 self-supervised learning methods across 3 GNN architectures reveals substantial differences in how representations are learned for spatial transcriptomics data. While definitive conclusions about method superiority require more comprehensive evaluation, several patterns emerged:\n\n- **Substantial method-backbone interactions** with the same SSL method behaving very differently depending on GNN backbone\n- **BYOL-SAGEConv shows balanced performance** across diverse metrics without over-optimizing for any single one\n- **Redundancy reduction methods** (VICReg, Barlow Twins) demonstrate consistency across architectures\n- **Evaluation challenges** highlight the difficulty of assessing representation quality through clustering and spatial metrics alone\n\nFuture work will focus on cross-tissue validation, biological validation through downstream tasks, and development of hybrid approaches that combine complementary strengths of different SSL families.\n\n---\n\n## Acknowledgments\n\nThis analysis leveraged:\n- **SiT Mouse Brain dataset** for spatial transcriptomics data\n- **PyTorch Geometric** for GNN implementations\n- **Scanpy** for preprocessing and visualization\n- **Scikit-learn** for evaluation metrics\n\n## References\n\n**SSL Methods**:\n- Chen et al. (2020) - SimCLR: A Simple Framework for Contrastive Learning\n- He et al. (2020) - MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\n- Grill et al. (2020) - BYOL: Bootstrap Your Own Latent\n- Caron et al. (2020) - SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\n- Chen & He (2021) - SimSiam: Exploring Simple Siamese Representation Learning\n- He et al. (2022) - MAE: Masked Autoencoders Are Scalable Vision Learners\n- Zbontar et al. (2021) - Barlow Twins: Self-Supervised Learning via Redundancy Reduction\n- Bardes et al. (2022) - VICReg: Variance-Invariance-Covariance Regularization\n\n**GNN Architectures**:\n- Hamilton et al. (2017) - GraphSAGE: Inductive Representation Learning on Large Graphs\n- Veličković et al. (2018) - GAT: Graph Attention Networks\n- Kipf & Welling (2017) - GCN: Semi-Supervised Classification with Graph Convolutional Networks\n\n**Spatial Transcriptomics**:\n- Lebrigand et al. (2023) - The spatial landscape of gene expression isoforms in tissue sections\n\n\n",
    "code": "var Component=(()=>{var p=Object.create;var a=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var v=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),b=(i,e)=>{for(var r in e)a(i,r,{get:e[r],enumerable:!0})},o=(i,e,r,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let t of g(e))!f.call(i,t)&&t!==r&&a(i,t,{get:()=>e[t],enumerable:!(s=m(e,t))||s.enumerable});return i};var y=(i,e,r)=>(r=i!=null?p(u(i)):{},o(e||!i||!i.__esModule?a(r,\"default\",{value:i,enumerable:!0}):r,i)),w=i=>o(a({},\"__esModule\",{value:!0}),i);var c=v((k,l)=>{l.exports=_jsx_runtime});var S={};b(S,{default:()=>d,frontmatter:()=>N});var n=y(c()),N={title:\"Comparing Self-Supervised Learning Methods for Spatial Transcriptomics\",summary:\"A systematic evaluation of 8 SSL methods with 3 GNN architectures on mouse brain spatial transcriptomics data\",status:\"completed\",role:\"Research & Analysis\",stack:[\"PyTorch\",\"PyTorch Geometric\",\"Python\",\"Self-Supervised Learning\",\"Graph Neural Networks\",\"Spatial Transcriptomics\"],tags:[\"deep learning\",\"self-supervised learning\",\"bioinformatics\",\"spatial transcriptomics\",\"representation learning\"],featured:!0,startDate:\"2025-09-16\"};function h(i){let e={a:\"a\",em:\"em\",h1:\"h1\",h2:\"h2\",h3:\"h3\",hr:\"hr\",img:\"img\",li:\"li\",ol:\"ol\",p:\"p\",span:\"span\",strong:\"strong\",table:\"table\",tbody:\"tbody\",td:\"td\",th:\"th\",thead:\"thead\",tr:\"tr\",ul:\"ul\",...i.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h1,{id:\"comparing-self-supervised-learning-methods-for-spatial-transcriptomics\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#comparing-self-supervised-learning-methods-for-spatial-transcriptomics\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Comparing Self-Supervised Learning Methods for Spatial Transcriptomics\"]}),`\n`,(0,n.jsx)(e.p,{children:\"A systematic evaluation exploring how different self-supervised learning approaches perform when combined with graph neural networks for learning spatial transcriptomics representations.\"}),`\n`,(0,n.jsxs)(e.h2,{id:\"table-of-contents\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#table-of-contents\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Table of Contents\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#introduction\",children:\"Introduction\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#methods\",children:\"Methods\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#results\",children:\"Results\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#key-findings\",children:\"Key Findings\"})}),`\n`,(0,n.jsx)(e.li,{children:(0,n.jsx)(e.a,{href:\"#future-directions\",children:\"Future Directions\"})}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"introduction\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#introduction\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Introduction\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"the-data-and-problem\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#the-data-and-problem\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"The Data and Problem\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Analyzed spatial transcriptomics data from the \",(0,n.jsx)(e.strong,{children:\"SiT Mouse Brain dataset\"}),\" (CBS1_illu) by \",(0,n.jsx)(e.a,{href:\"https://doi.org/10.1093/nar/gkad169\",children:\"Lebrigand et al., 2023\"}),\", which captures gene expression patterns with spatial context from mouse brain samples. The dataset comprises:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"2,560 spatial spots\"}),\" representing distinct tissue locations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"31,053 genes\"}),\", filtered to \",(0,n.jsx)(e.strong,{children:\"3,000 highly variable genes (HVGs)\"})]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Spatial coordinates\"}),\" preserving tissue architecture\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"13 annotated cell types/regions\"}),\" including CA1/CA2, CA3, DG, Hippocampus, Hypothalamus, Isocortex, and others\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/projects/sit_explore/CBS1_anno.jpg\",alt:\"SiT CBS1_illu_anno\"})}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Research Question\"}),\": How do different self-supervised learning (SSL) approaches perform when combined with graph neural networks (GNNs) for learning spatial transcriptomics representations?\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"graph-construction\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#graph-construction\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Graph Construction\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"As detailed in my \",(0,n.jsx)(e.a,{href:\"/projects/gnn-spatial-transcriptomics\",children:\"previous work on GNNs for spatial transcriptomics\"}),\", I constructed a \",(0,n.jsx)(e.strong,{children:\"k-nearest neighbor spatial graph\"}),\" (k=8) based on Euclidean distances between spot coordinates, resulting in \",(0,n.jsx)(e.strong,{children:\"2,560 nodes\"}),\" and \",(0,n.jsx)(e.strong,{children:\"40,960 edges\"}),\".\"]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"methods\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#methods\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Methods\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"gnn-architectures\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#gnn-architectures\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"GNN Architectures\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Three GNN architectures were evaluated as encoder backbones:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"GraphSAGE (SAGEConv)\"}),\": Samples and aggregates features from neighbors using mean pooling\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Graph Attention Networks (GATConv)\"}),\": Learns attention weights to weigh neighbor importance (4 attention heads)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Graph Convolutional Networks (GCNConv)\"}),\": Applies spectral graph convolutions for feature aggregation\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Architecture specifications\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"2 GNN layers\"}),`\n`,(0,n.jsx)(e.li,{children:\"Hidden dimension: 256\"}),`\n`,(0,n.jsx)(e.li,{children:\"Projection dimension: 64\"}),`\n`,(0,n.jsx)(e.li,{children:\"Batch normalization and dropout (0.1) between layers\"}),`\n`]}),`\n`,(0,n.jsxs)(e.h3,{id:\"self-supervised-learning-methods\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#self-supervised-learning-methods\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Self-Supervised Learning Methods\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Eight state-of-the-art SSL methods were compared across different families:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Contrastive Learning\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SimCLR\"}),\": Contrastive learning using NT-Xent loss (temperature=0.2)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SwAV\"}),\": Swapping assignments between views using optimal transport (512 prototypes)\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Momentum-based Methods\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"BYOL\"}),\": Bootstrap Your Own Latent without negative pairs (momentum=0.99)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"MoCo\"}),\": Momentum contrast with a queue of negative samples (queue size=4096, momentum=0.99)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SimSiam\"}),\": Simple Siamese Networks with stop-gradient\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Reconstruction-based\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"MAE\"}),\": Masked Autoencoder reconstructing masked gene expressions (mask ratio=0.75)\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Redundancy Reduction\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Barlow Twins\"}),\": Self-supervised learning via redundancy reduction (\\u03BB=0.005)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"VICReg\"}),\": Variance-Invariance-Covariance Regularization (\\u03BB_inv=25, \\u03BB_var=25, \\u03BB_cov=1)\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Data Augmentation\"}),\": Gene dropout (10%) and Gaussian noise addition (scale=0.005)\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Training\"}),\": 20 epochs, batch size 256, AdamW optimizer (lr=1e-4, weight decay=1e-5)\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"evaluation-metrics\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#evaluation-metrics\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Evaluation Metrics\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Five complementary metrics were used to evaluate \",(0,n.jsx)(e.strong,{children:\"24 method-backbone combinations\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"AMI/NMI (Adjusted/Normalized Mutual Information)\"}),\": Clustering agreement with ground truth annotations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Silhouette Score\"}),\": Internal cluster cohesion and separation\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Moran's I\"}),\": Global spatial autocorrelation (higher = stronger spatial coherence)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Geary's C\"}),\": Alternative spatial autocorrelation measure (lower = stronger spatial coherence)\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Important Note\"}),\": These metrics provide a \",(0,n.jsx)(e.strong,{children:\"partial view\"}),\" of model performance. They don't capture robustness to batch effects, transferability to downstream tasks, biological interpretability, or performance on rare cell types.\"]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"results\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#results\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Results\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"clustering-visualizations-by-backbone\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#clustering-visualizations-by-backbone\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Clustering Visualizations by Backbone\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The spatial clustering results reveal substantial qualitative differences across methods and backbones:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/SAGEConv.jpg\",alt:\"SAGEConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 1: Leiden clustering results for all SSL methods using SAGEConv backbone. SAGEConv-based methods tend to produce more fragmented spatial patterns with sharper local transitions, potentially preserving fine-grained local heterogeneity.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/GATConc.jpg\",alt:\"GATConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 2: Leiden clustering results for all SSL methods using GATConv backbone. GATConv shows intermediate behavior with learned attention weights adding flexibility to adapt to local structure.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/GCNConv.jpg\",alt:\"GCNConv Clustering Results\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 3: Leiden clustering results for all SSL methods using GCNConv backbone. GCNConv-based methods generally show more spatially contiguous clusters with smoother boundaries and stronger delineation along major anatomical boundaries.\"})]}),`\n`,(0,n.jsxs)(e.h3,{id:\"quantitative-performance-metrics\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#quantitative-performance-metrics\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Quantitative Performance Metrics\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/method_comparison.png\",alt:\"Method Comparison\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 4: Average performance by SSL method across clustering and spatial metrics. Redundancy reduction methods (VICReg, Barlow Twins) show higher clustering agreement, while methods vary substantially in spatial autocorrelation.\"})]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/backbone_comparison.png\",alt:\"Backbone Comparison\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 5: Average performance by GNN backbone. GCNConv shows very low variance in spatial metrics, suggesting strong spatial smoothing. SAGEConv exhibits highest variance across methods, indicating SSL objective matters more for this backbone.\"})]}),`\n`,(0,n.jsxs)(e.h3,{id:\"method-performance-summary\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#method-performance-summary\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Method Performance Summary\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Average behavior across all three GNN backbones (mean \\xB1 std):\"}),`\n`,(0,n.jsxs)(e.table,{children:[(0,n.jsx)(e.thead,{children:(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.th,{children:\"Method\"}),(0,n.jsx)(e.th,{children:\"AMI\"}),(0,n.jsx)(e.th,{children:\"NMI\"}),(0,n.jsx)(e.th,{children:\"Silhouette\"}),(0,n.jsx)(e.th,{children:\"Moran's I\"}),(0,n.jsx)(e.th,{children:\"Geary's C\"})]})}),(0,n.jsxs)(e.tbody,{children:[(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"VICReg\"}),(0,n.jsx)(e.td,{children:\"0.566\\xB10.095\"}),(0,n.jsx)(e.td,{children:\"0.572\\xB10.094\"}),(0,n.jsx)(e.td,{children:\"0.283\\xB10.023\"}),(0,n.jsx)(e.td,{children:\"0.847\\xB10.072\"}),(0,n.jsx)(e.td,{children:\"0.153\\xB10.070\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"Barlow Twins\"}),(0,n.jsx)(e.td,{children:\"0.558\\xB10.036\"}),(0,n.jsx)(e.td,{children:\"0.563\\xB10.036\"}),(0,n.jsx)(e.td,{children:\"0.266\\xB10.024\"}),(0,n.jsx)(e.td,{children:\"0.855\\xB10.092\"}),(0,n.jsx)(e.td,{children:\"0.145\\xB10.091\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SwAV\"}),(0,n.jsx)(e.td,{children:\"0.529\\xB10.047\"}),(0,n.jsx)(e.td,{children:\"0.536\\xB10.046\"}),(0,n.jsx)(e.td,{children:\"0.269\\xB10.042\"}),(0,n.jsx)(e.td,{children:\"0.830\\xB10.108\"}),(0,n.jsx)(e.td,{children:\"0.172\\xB10.106\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"BYOL\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.524\\xB10.023\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.531\\xB10.023\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.271\\xB10.027\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.819\\xB10.121\"})}),(0,n.jsx)(e.td,{children:(0,n.jsx)(e.strong,{children:\"0.184\\xB10.116\"})})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"MoCo\"}),(0,n.jsx)(e.td,{children:\"0.515\\xB10.067\"}),(0,n.jsx)(e.td,{children:\"0.522\\xB10.066\"}),(0,n.jsx)(e.td,{children:\"0.184\\xB10.027\"}),(0,n.jsx)(e.td,{children:\"0.781\\xB10.151\"}),(0,n.jsx)(e.td,{children:\"0.224\\xB10.148\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SimCLR\"}),(0,n.jsx)(e.td,{children:\"0.506\\xB10.022\"}),(0,n.jsx)(e.td,{children:\"0.513\\xB10.022\"}),(0,n.jsx)(e.td,{children:\"0.186\\xB10.033\"}),(0,n.jsx)(e.td,{children:\"0.791\\xB10.130\"}),(0,n.jsx)(e.td,{children:\"0.210\\xB10.129\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"SimSiam\"}),(0,n.jsx)(e.td,{children:\"0.479\\xB10.016\"}),(0,n.jsx)(e.td,{children:\"0.486\\xB10.016\"}),(0,n.jsx)(e.td,{children:\"0.247\\xB10.018\"}),(0,n.jsx)(e.td,{children:\"0.809\\xB10.120\"}),(0,n.jsx)(e.td,{children:\"0.187\\xB10.119\"})]}),(0,n.jsxs)(e.tr,{children:[(0,n.jsx)(e.td,{children:\"MAE\"}),(0,n.jsx)(e.td,{children:\"0.256\\xB10.018\"}),(0,n.jsx)(e.td,{children:\"0.265\\xB10.018\"}),(0,n.jsx)(e.td,{children:\"0.328\\xB10.006\"}),(0,n.jsx)(e.td,{children:\"0.806\\xB10.097\"}),(0,n.jsx)(e.td,{children:\"0.189\\xB10.096\"})]})]})]}),`\n`,(0,n.jsxs)(e.h3,{id:\"metric-relationships\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#metric-relationships\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Metric Relationships\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.img,{src:\"/projects/sit_explore/metrics_scatterplots.png\",alt:\"Metric Scatter Plots\"}),`\n`,(0,n.jsx)(e.em,{children:\"Figure 6: Relationships between clustering quality and spatial coherence metrics. AMI vs. Moran's I show positive correlation (\\u03C1\\u22480.75), though this may reflect GCNConv's strong influence on both metrics.\"})]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"key-findings\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#key-findings\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Key Findings\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"observed-patterns\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#observed-patterns\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Observed Patterns\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"BYOL with SAGEConv shows promise\"}),\": This combination achieves balanced performance across metrics (AMI=0.510, NMI=0.516, Silhouette=0.254, Moran's I=0.683) without over-optimizing for any single one, suggesting potential for further investigation.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Redundancy reduction methods show consistency\"}),\": VICReg and Barlow Twins exhibit higher AMI/NMI values and more consistent behavior across backbones (lower std), suggesting robust learning dynamics.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"BYOL demonstrates remarkable consistency\"}),\": With std=0.023 for AMI across different GNN architectures, BYOL's momentum-based approach appears robust to architectural choices.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"MAE exhibits a paradox\"}),`: Highest Silhouette scores (0.328) but lowest clustering agreement (AMI=0.256). This suggests it learns internally coherent representations that don't align with the provided annotations. It maybe suffering from the \"noise\"?`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Strong method-backbone interactions\"}),\": The same SSL method behaves very differently depending on GNN backbone, with variance up to 0.124 in AMI, indicating that architecture choice significantly influences representation learning.\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"gnn-backbone-trade-offs\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#gnn-backbone-trade-offs\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"GNN Backbone Trade-offs\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"GCNConv\"}),\": Shows very low variance in spatial metrics (std=0.007 for Moran's I), suggesting spectral operations impose strong spatial smoothing regardless of SSL method. This high spatial coherence may be desirable or may indicate over-smoothing.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SAGEConv\"}),\": Exhibits comparable AMI to GCNConv (0.510 vs. 0.507) but lower spatial autocorrelation (Moran's I=0.695). \",(0,n.jsx)(e.strong,{children:\"Highest variance across methods\"}),\" (std=0.124) indicates SSL objective matters more for this backbone, potentially preserving local heterogeneity (can also be observed from Figure 1~3).\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"GATConv\"}),\": Shows intermediate values across all metrics with learned attention weights providing flexibility to adapt to local structure. As a side project, I experimented with adding regional attention mechanisms that provide the model with global spatial relationships, which significantly improved GAT's performance across all metrics.\"]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"key-findings-1\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#key-findings-1\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Key Findings\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"critical-limitations\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#critical-limitations\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Critical Limitations\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This exploratory study has important limitations that constrain conclusions:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Evaluation Limitations\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:'Metrics are proxies, not ground truth\\u2014AMI/NMI assume the 13 annotated regions are \"correct,\" but annotations may be incomplete or subjective'}),`\n`,(0,n.jsx)(e.li,{children:\"Single dataset from mouse brain may not generalize to other tissues or organisms\"}),`\n`,(0,n.jsx)(e.li,{children:\"Limited hyperparameter exploration (only 20 epochs, fixed augmentation parameters)\"}),`\n`,(0,n.jsx)(e.li,{children:\"No downstream task evaluation for actual biological utility\"}),`\n`,(0,n.jsx)(e.li,{children:\"Small dataset (2,560 spots) may not reveal scalability issues\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Interpretation Challenges\"}),\": High Moran's I could reflect beneficial spatial structure or excessive smoothing. High Silhouette doesn't guarantee biological relevance. Therefore, these metrics primarily identify differences in learned representations rather than definitively ranking method quality.\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"potential-hybrid-approaches\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#potential-hybrid-approaches\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Potential Hybrid Approaches\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Given different strengths of each method family, combining approaches may be promising:\"}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SimCLR + Barlow Twins\"}),\": Combine discriminative learning through contrastive loss with decorrelation to prevent feature redundancy. This may achieve both strong discrimination and feature diversity without collapse.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"BYOL + VICReg\"}),\": Add VICReg's variance/covariance terms to BYOL's predictor objective to provide explicit collapse prevention mechanism while maintaining momentum-based stability.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Spatial-aware SSL\"}),\": Add explicit spatial regularization term to existing methods to test whether explicit spatial terms improve over implicit (GNN-based) spatial encoding.\"]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"future-directions\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#future-directions\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Future Directions\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"next-steps\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#next-steps\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Next Steps\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Cross-tissue validation\"}),\": The single-dataset limitation is this study's most critical weakness. Evaluation on diverse tissues (liver, heart, tumor microenvironments) and larger datasets (10,000+ spots) is essential to assess generalizability and scalability.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Biological validation\"}),\": Beyond clustering metrics, I plan to evaluate differential gene expression, pathway enrichment, rare cell type recovery, and spatial trajectory inference quality to assess actual biological utility.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Hybrid method development\"}),\": Systematic investigation of combined approaches (SimCLR+Barlow Twins, BYOL+VICReg) with careful hyperparameter tuning may leverage complementary strengths.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Downstream task evaluation\"}),\": Test representations on actual biological questions including differential expression analysis, cell-cell communication, and trajectory inference.\"]}),`\n`,(0,n.jsxs)(e.h3,{id:\"open-questions\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#open-questions\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Open Questions\"]}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Why does BYOL-SAGEConv show such balanced behavior across metrics?\"}),`\n`,(0,n.jsx)(e.li,{children:\"Can we design metrics that better reflect biological utility rather than statistical properties?\"}),`\n`,(0,n.jsx)(e.li,{children:\"How do methods perform on rare cell types not well-represented in the dataset?\"}),`\n`,(0,n.jsx)(e.li,{children:\"What is the minimal dataset size needed for each method to perform effectively?\"}),`\n`,(0,n.jsx)(e.li,{children:\"Can we predict which method suits a given tissue type a priori?\"}),`\n`,(0,n.jsx)(e.li,{children:`Can we treat gene expression patterns as samples instead of spots? Currently, each spot (with its gene expression vector) is treated as a sample. An alternative approach would be to treat each gene's expression pattern across all spots as a sample\\u2014essentially viewing each gene as an \"image\" where pixel intensities represent expression levels at different spatial locations. This gene-centric perspective might reveal different biological insights about co-expression patterns and spatial gene regulatory networks.`}),`\n`]}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"conclusion\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#conclusion\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Conclusion\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This systematic comparison of 8 self-supervised learning methods across 3 GNN architectures reveals substantial differences in how representations are learned for spatial transcriptomics data. While definitive conclusions about method superiority require more comprehensive evaluation, several patterns emerged:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Substantial method-backbone interactions\"}),\" with the same SSL method behaving very differently depending on GNN backbone\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"BYOL-SAGEConv shows balanced performance\"}),\" across diverse metrics without over-optimizing for any single one\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Redundancy reduction methods\"}),\" (VICReg, Barlow Twins) demonstrate consistency across architectures\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Evaluation challenges\"}),\" highlight the difficulty of assessing representation quality through clustering and spatial metrics alone\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Future work will focus on cross-tissue validation, biological validation through downstream tasks, and development of hybrid approaches that combine complementary strengths of different SSL families.\"}),`\n`,(0,n.jsx)(e.hr,{}),`\n`,(0,n.jsxs)(e.h2,{id:\"acknowledgments\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#acknowledgments\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Acknowledgments\"]}),`\n`,(0,n.jsx)(e.p,{children:\"This analysis leveraged:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"SiT Mouse Brain dataset\"}),\" for spatial transcriptomics data\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"PyTorch Geometric\"}),\" for GNN implementations\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Scanpy\"}),\" for preprocessing and visualization\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\"Scikit-learn\"}),\" for evaluation metrics\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"references\",children:[(0,n.jsx)(e.a,{className:\"anchor\",href:\"#references\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"References\"]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"SSL Methods\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Chen et al. (2020) - SimCLR: A Simple Framework for Contrastive Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"He et al. (2020) - MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"Grill et al. (2020) - BYOL: Bootstrap Your Own Latent\"}),`\n`,(0,n.jsx)(e.li,{children:\"Caron et al. (2020) - SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments\"}),`\n`,(0,n.jsx)(e.li,{children:\"Chen & He (2021) - SimSiam: Exploring Simple Siamese Representation Learning\"}),`\n`,(0,n.jsx)(e.li,{children:\"He et al. (2022) - MAE: Masked Autoencoders Are Scalable Vision Learners\"}),`\n`,(0,n.jsx)(e.li,{children:\"Zbontar et al. (2021) - Barlow Twins: Self-Supervised Learning via Redundancy Reduction\"}),`\n`,(0,n.jsx)(e.li,{children:\"Bardes et al. (2022) - VICReg: Variance-Invariance-Covariance Regularization\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"GNN Architectures\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Hamilton et al. (2017) - GraphSAGE: Inductive Representation Learning on Large Graphs\"}),`\n`,(0,n.jsx)(e.li,{children:\"Veli\\u010Dkovi\\u0107 et al. (2018) - GAT: Graph Attention Networks\"}),`\n`,(0,n.jsx)(e.li,{children:\"Kipf & Welling (2017) - GCN: Semi-Supervised Classification with Graph Convolutional Networks\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.strong,{children:\"Spatial Transcriptomics\"}),\":\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Lebrigand et al. (2023) - The spatial landscape of gene expression isoforms in tissue sections\"}),`\n`]})]})}function d(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,{...i,children:(0,n.jsx)(h,{...i})}):h(i)}return w(S);})();\n;return Component;"
  },
  "_id": "projects/gnn-ssl-sit.mdx",
  "_raw": {
    "sourceFilePath": "projects/gnn-ssl-sit.mdx",
    "sourceFileName": "gnn-ssl-sit.mdx",
    "sourceFileDir": "projects",
    "contentType": "mdx",
    "flattenedPath": "projects/gnn-ssl-sit"
  },
  "type": "Project",
  "url": "/projects/gnn-ssl-sit",
  "slug": "gnn-ssl-sit"
}